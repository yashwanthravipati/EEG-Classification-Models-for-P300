{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc2ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Input, Flatten\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def EEGInception(input_time=1000, fs=128, ncha=8, filters_per_branch=8,\n",
    "                 scales_time=(500, 250, 125), dropout_rate=0.25,\n",
    "                 activation='elu', n_classes=2, learning_rate=0.001):\n",
    "    \n",
    "    \"\"\"Keras implementation of EEG-Inception. All hyperparameters and\n",
    "    architectural choices are explained in the original article:\n",
    "    https://doi.org/10.1109/TNSRE.2020.3048106\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_time : int\n",
    "        EEG epoch time in milliseconds\n",
    "    fs : int\n",
    "        Sample rate of the EEG\n",
    "    ncha :\n",
    "        Number of input channels\n",
    "    filters_per_branch : int\n",
    "        Number of filters in each Inception branch\n",
    "    scales_time : list\n",
    "        Temporal scale (ms) of the convolutions on each Inception module.\n",
    "        This parameter determines the kernel sizes of the filters\n",
    "    dropout_rate : float\n",
    "        Dropout rate\n",
    "    activation : str\n",
    "        Activation\n",
    "    n_classes : int\n",
    "        Number of output classes\n",
    "    learning_rate : float\n",
    "        Learning rate\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.models.Model\n",
    "        Keras model already compiled and ready to work\n",
    "    \"\"\"\n",
    "\n",
    "    # ============================= CALCULATIONS ============================= #\n",
    "    input_samples = int(input_time * fs / 1000)\n",
    "    scales_samples = [int(s * fs / 1000) for s in scales_time]\n",
    "\n",
    "    # ================================ INPUT ================================= #\n",
    "    input_layer = Input((input_samples, ncha, 1))\n",
    "\n",
    "    # ========================== BLOCK 1: INCEPTION ========================== #\n",
    "    b1_units = list()\n",
    "    for i in range(len(scales_samples)):\n",
    "        unit = Conv2D(filters=filters_per_branch,\n",
    "                      kernel_size=(scales_samples[i], 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      padding='same')(input_layer)\n",
    "        unit = BatchNormalization()(unit)\n",
    "        unit = Activation(activation)(unit)\n",
    "        unit = Dropout(dropout_rate)(unit)\n",
    "\n",
    "        unit = DepthwiseConv2D((1, ncha),\n",
    "                               use_bias=False,\n",
    "                               depth_multiplier=2,\n",
    "                               depthwise_constraint=max_norm(1.))(unit)\n",
    "        unit = BatchNormalization()(unit)\n",
    "        unit = Activation(activation)(unit)\n",
    "        unit = Dropout(dropout_rate)(unit)\n",
    "\n",
    "        b1_units.append(unit)\n",
    "\n",
    "    # Concatenation\n",
    "    b1_out = keras.layers.concatenate(b1_units, axis=3)\n",
    "    b1_out = AveragePooling2D((4, 1))(b1_out)\n",
    "\n",
    "    # ========================== BLOCK 2: INCEPTION ========================== #\n",
    "    b2_units = list()\n",
    "    for i in range(len(scales_samples)):\n",
    "        unit = Conv2D(filters=filters_per_branch,\n",
    "                      kernel_size=(int(scales_samples[i]/4), 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      use_bias=False,\n",
    "                      padding='same')(b1_out)\n",
    "        unit = BatchNormalization()(unit)\n",
    "        unit = Activation(activation)(unit)\n",
    "        unit = Dropout(dropout_rate)(unit)\n",
    "\n",
    "        b2_units.append(unit)\n",
    "\n",
    "    # Concatenate + Average pooling\n",
    "    b2_out = keras.layers.concatenate(b2_units, axis=3)\n",
    "    b2_out = AveragePooling2D((2, 1))(b2_out)\n",
    "\n",
    "    # ============================ BLOCK 3: OUTPUT =========================== #\n",
    "    b3_u1 = Conv2D(filters=int(filters_per_branch*len(scales_samples)/2),\n",
    "                   kernel_size=(8, 1),\n",
    "                   kernel_initializer='he_normal',\n",
    "                   use_bias=False,\n",
    "                   padding='same')(b2_out)\n",
    "    b3_u1 = BatchNormalization()(b3_u1)\n",
    "    b3_u1 = Activation(activation)(b3_u1)\n",
    "    b3_u1 = AveragePooling2D((2, 1))(b3_u1)\n",
    "    b3_u1 = Dropout(dropout_rate)(b3_u1)\n",
    "\n",
    "    b3_u2 = Conv2D(filters=int(filters_per_branch*len(scales_samples)/4),\n",
    "                   kernel_size=(4, 1),\n",
    "                   kernel_initializer='he_normal',\n",
    "                   use_bias=False,\n",
    "                   padding='same')(b3_u1)\n",
    "    b3_u2 = BatchNormalization()(b3_u2)\n",
    "    b3_u2 = Activation(activation)(b3_u2)\n",
    "    b3_u2 = AveragePooling2D((2, 1))(b3_u2)\n",
    "    b3_out = Dropout(dropout_rate)(b3_u2)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Flatten()(b3_out)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(output_layer)\n",
    "\n",
    "    # ================================ MODEL ================================= #\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9,\n",
    "                                      beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "debc6b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PF32_2016_11_30_train32FFS001R02.dat', 'PF32_2016_11_30_train32FFS001R03.dat', 'pf_training.prm', 'PF32_2016_11_30_train32FFS001R04.dat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    }
   ],
   "source": [
    "# Code to read the files\n",
    "# The files are stores in the eeg-data folder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "subject_name = 'subject_020'\n",
    "src_dir = 'Desktop/eeg-data/Subjects-Data/' + subject_name +'/'\n",
    "list_dir = os.listdir(src_dir)\n",
    "print (list_dir)\n",
    "from BCI2kReader import BCI2kReader as b2k \n",
    "subject_to_signals =  {}  #dictionary; key= subject, value = data\n",
    "\n",
    "for subject_dir in os.listdir(src_dir)[0:85]:\n",
    "   \n",
    "    if not subject_dir.startswith(\".\"):\n",
    "            if (subject_dir.endswith(\".dat\")):\n",
    "                with b2k.BCI2kReader(src_dir+subject_dir, \"training1.dat\") as file: \n",
    "                    subject_to_signals[subject_dir] = file.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9f20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject_008', '.DS_Store', 'subject_009', 'subject_007', 'subject_014', 'subject_013', 'subject_012', 'subject_015', 'subject_002', 'subject_005', 'subject_004', 'subject_019', 'subject_017', 'subject_016', 'subject_011', 'subject_018']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "import os\n",
    "#subject_name = 'subject_048'\n",
    "src_dir = '../Desktop/eeg-data/Bagging-Data/' \n",
    "#out_dir = 'Desktop/eeg-data/output/'+ subject_name +'_results.pdf'\n",
    "list_dir = os.listdir(src_dir)\n",
    "print (list_dir)\n",
    "from BCI2kReader import BCI2kReader as b2k \n",
    "subject_to_signals =  {}  #dictionary; key= subject, value = data\n",
    "\n",
    "for sub_root_dir in os.listdir(src_dir):\n",
    "\n",
    "    if not sub_root_dir.startswith(\".\"):\n",
    "        \n",
    "        for subject_dir in os.listdir(src_dir+sub_root_dir+'/')[0:85]:\n",
    "   \n",
    "            if not subject_dir.startswith(\".\"):\n",
    "                    if (subject_dir.endswith(\".dat\")):\n",
    "                        with b2k.BCI2kReader(src_dir+sub_root_dir+'/'+subject_dir, \"BaggingTrain.dat\") as file: \n",
    "                            subject_to_signals[subject_dir] = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b711e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(42000, 192, 32)\n",
      "(42000,)\n",
      "(42000, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training\n",
    "# Train data is for EEGNet trainng & testing as well as RG+xDawn evaluation\n",
    "#192 temporal data points are used for EEGNet \n",
    "#Iterative work pointed that 128 temporal points for ech event produced gives best LDA performance\n",
    "\n",
    "window = 192   #Signal time series window\n",
    "sht_window = 128 # shoretened window for LDA analysis\n",
    "subject_name = []\n",
    "z_score = []\n",
    "zerozscore = []\n",
    "#print (subject_to_signals)\n",
    "array_elements = sht_window * 32\n",
    "\n",
    "#Train_data = np.array(np.empty((0,32,window), float))  # Training data array initialization\n",
    "Train_data = np.array(np.empty((0,window,32), float))  # Training data array initialization\n",
    "\n",
    "Train_labels = []   # Training label data initialization\n",
    "Train_data_flattened = np.array(np.empty((0,array_elements), float))  # Training data array initialization\n",
    "\n",
    "\n",
    "\n",
    "for subject, my_signals in subject_to_signals.items():\n",
    "   # print (my_signals)\n",
    "    #Train_data_temp = np.array(np.empty((0,32,window), float))  # Training data array initialization\n",
    "    Train_data_temp = np.array(np.empty((0,window,32), float))  # Training data array initialization\n",
    "    \n",
    "    Train_labels_temp = []   # Training label data initialization\n",
    "    Train_data_flattened_temp = np.array(np.empty((0,array_elements), float))  # Training data array initialization\n",
    "\n",
    "    stimuluscode = (my_signals[1]['StimulusCode']) #ndarrays ; target \n",
    "    stimulustype = (my_signals[1]['StimulusType']) #p3label\n",
    "    data = stimuluscode[0] #target numbers\n",
    "    data_label = stimulustype[0] #p3label numbers\n",
    "    rownum = len(data)\n",
    "    labelrow = len(data_label)\n",
    "    zerozscore = (-1*np.mean(my_signals[0])/(my_signals[0]).std())\n",
    "    \n",
    "    change = [] #indexes of 0 where next index is nonzero for target\n",
    "    for x in range(rownum-1):    \n",
    "        if bool(data.item(x) == 0) and bool(data.item(x + 1) != 0): \n",
    "                change.append(x)\n",
    "      \n",
    "    \n",
    "    \n",
    "    attended = [] #indexes where p3label value is 1\n",
    "    nonattended = [] #indexes where p3label value is 0\n",
    "\n",
    "\n",
    "    nonattended_count =1\n",
    "   \n",
    "    for x in range(len(change)): \n",
    "      \n",
    "        attended_values = np.empty((0,window), float) #2D array with train data each row in same a time frame\n",
    "        nonattended_values = np.empty((0,window), float)\n",
    "        attended_values_sht = np.empty((0,sht_window), float) #2D array with train data each row in same a time frame\n",
    "        nonattended_values_sht = np.empty((0,sht_window), float)\n",
    " \n",
    "        if bool(data_label.item(change[x] + 1) == 0): \n",
    "            nonattended_count =nonattended_count +1    \n",
    "            nonattended.append(change[x])\n",
    "            Train_labels_temp.append(int(0))\n",
    "            for num in range(len(my_signals[0])):\n",
    "                electrode = my_signals[0][num]\n",
    "                zelectrode = stats.zscore(my_signals[0][num])\n",
    "                nonattendedtemp = []\n",
    "                nonattendedtemp_sht =[]\n",
    "                if (change[x] + window) > len(zelectrode):\n",
    "                    addtime = len(zelectrode) - (change[x])            \n",
    "                    for y in range(addtime):\n",
    "                        nonattendedtemp.append(zelectrode[change[x] + y])\n",
    "                    for y in range(sht_window):\n",
    "                        nonattendedtemp_sht.append(zelectrode[change[x] + y])\n",
    "                    nonattended_values_sht = np.append(nonattended_values_sht, np.array([nonattendedtemp_sht]), axis = 0)               \n",
    "                    nonattended_values = np.append(nonattended_values, np.array([nonattendedtemp]), axis = 0)\n",
    "                else:\n",
    "                    for y in range(window):\n",
    "                        nonattendedtemp.append(zelectrode[change[x] + y])\n",
    "                    for y in range(sht_window):\n",
    "                        nonattendedtemp_sht.append(zelectrode[change[x] + y])\n",
    "                nonattended_values = np.append(nonattended_values, np.array([nonattendedtemp]), axis = 0)\n",
    "                nonattended_values_sht = np.append(nonattended_values_sht, np.array([nonattendedtemp_sht]), axis = 0)               \n",
    "            #if nonattended_count % 5 == 0:\n",
    "            Train_data_flattened_temp = np.append(Train_data_flattened_temp, np.array([nonattended_values_sht.flatten()]), axis=0)\n",
    "            Train_data_temp = np.append(Train_data_temp,np.array([nonattended_values.T]), axis=0)\n",
    "        else: \n",
    "            attended.append(change[x] + 1) \n",
    "            Train_labels_temp.append(int(1))\n",
    "          \n",
    "            for num in range(len(my_signals[0])):\n",
    "                electrode = my_signals[0][num]\n",
    "                zelectrode = stats.zscore(my_signals[0][num])\n",
    "                attendedtemp = []\n",
    "                attendedtemp_sht = []\n",
    "        \n",
    "                for y in range(window): \n",
    "                    attendedtemp.append(zelectrode[change[x] + y])\n",
    "                for y in range(sht_window): \n",
    "                    attendedtemp_sht.append(zelectrode[change[x] + y])\n",
    "\n",
    "                attended_values = np.append(attended_values, np.array([attendedtemp]), axis = 0)\n",
    "                attended_values_sht = np.append(attended_values_sht, np.array([attendedtemp_sht]), axis = 0)\n",
    "\n",
    "            Train_data_flattened_temp = np.append( Train_data_flattened_temp, np.array([attended_values_sht.flatten()]), axis=0)\n",
    "            Train_data_temp = np.append( Train_data_temp,np.array([attended_values.T]), axis=0)        \n",
    "    \n",
    "    Train_data_flattened = np.concatenate((Train_data_flattened, Train_data_flattened_temp),axis=0) # format is in (trials, channels, samples)\n",
    "    Train_data = np.concatenate((Train_data, Train_data_temp),axis=0) # format is in (trials, channels, samples)\n",
    "    Train_labels = np.concatenate((Train_labels, Train_labels_temp),axis=0) \n",
    "    \n",
    "    print(\"no of labled P300 events:\"+str(len(attended)))\n",
    "    print(\"no of non_attended P300 events:\"+str(len(nonattended)))\n",
    "    \n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_labels))\n",
    "print(np.shape(Train_data_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b2e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import h5py, os\n",
    "#from EEGInception import EEGInception\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,RepeatedStratifiedKFold,GridSearchCV\n",
    "\n",
    "#%% PARAMETERS\n",
    "\n",
    "#dataset_path = 'Desktop/GIB-UVA ERP-BCI.hdf5'\n",
    "\n",
    "#%% HYPERPARAMETERS\n",
    "\n",
    "input_time = 1000\n",
    "fs = 192\n",
    "n_cha = 32\n",
    "filters_per_branch = 8\n",
    "scales_time = (500, 250, 125)\n",
    "dropout_rate = 0.25\n",
    "activation = 'elu'\n",
    "n_classes = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "#%% LOAD DATASET\n",
    "#hf = h5py.File(dataset_path, 'r')\n",
    "#features = np.array(hf.get(\"features\"))\n",
    "#erp_labels = np.array(hf.get(\"erp_labels\"))\n",
    "#codes = np.array(hf.get(\"codes\"))\n",
    "#trials = np.array(hf.get(\"trials\"))\n",
    "#sequences = np.array(hf.get(\"sequences\"))\n",
    "#matrix_indexes = np.array(hf.get(\"matrix_indexes\"))\n",
    "#run_indexes = np.array(hf.get(\"run_indexes\"))\n",
    "#subjects = np.array(hf.get(\"subjects\"))\n",
    "#database_ids = np.array(hf.get(\"database_ids\"))\n",
    "#target = np.array(hf.get(\"target\"))\n",
    "#matrix_dims = np.array(hf.get(\"matrix_dims\"))\n",
    "#hf.close()\n",
    "\n",
    "#End_index = len(Train_labels)\n",
    "#Train_index = (int) (End_index * 0.8)\n",
    "\n",
    "#features=Train_data[0:Train_index,]\n",
    "#erp_labels = Train_labels[0:Train_index,]\n",
    "#X_test = Train_data[Train_index:,]\n",
    "#Y_test = Train_labels[Train_index:]\n",
    "\n",
    "features, X_test, erp_labels, Y_test = train_test_split(Train_data, Train_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "#%% PREPARE FEATURES AND LABELS\n",
    "# Reshape epochs for EEG-Inception\n",
    "X_test = X_test.reshape(\n",
    "    (X_test.shape[0], X_test.shape[1],\n",
    "     X_test.shape[2], 1)\n",
    ")\n",
    "features = features.reshape(\n",
    "    (features.shape[0], features.shape[1],\n",
    "     features.shape[2], 1)\n",
    ")\n",
    "\n",
    "# One hot encoding of labels\n",
    "def one_hot_labels(caategorical_labels):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    on_hot_labels = enc.fit_transform(\n",
    "        caategorical_labels.reshape(-1, 1)).toarray()\n",
    "    return on_hot_labels\n",
    "\n",
    "\n",
    "train_erp_labels = one_hot_labels(erp_labels)\n",
    "Y_test = one_hot_labels(Y_test)    \n",
    "\n",
    "#%%  TRAINING\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29a177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 16:52:05.794216: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 192, 32, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 192, 32, 8)   776         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 192, 32, 8)   392         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 192, 32, 8)   200         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 192, 32, 8)  32          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 192, 32, 8)  32          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 192, 32, 8)  32          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 192, 32, 8)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 192, 32, 8)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 192, 32, 8)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 192, 32, 8)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 192, 32, 8)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 192, 32, 8)   0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 192, 1, 16)  512         ['dropout[0][0]']                \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 192, 1, 16)  512         ['dropout_2[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (DepthwiseC  (None, 192, 1, 16)  512         ['dropout_4[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 192, 1, 16)  64          ['depthwise_conv2d[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 192, 1, 16)  64          ['depthwise_conv2d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 192, 1, 16)  64          ['depthwise_conv2d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 192, 1, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 192, 1, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 192, 1, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 192, 1, 16)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 192, 1, 16)   0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 192, 1, 16)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192, 1, 48)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout_3[0][0]',              \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 48, 1, 48)   0           ['concatenate[0][0]']            \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 48, 1, 8)     9216        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 48, 1, 8)     4608        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 48, 1, 8)     2304        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 48, 1, 8)    32          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 48, 1, 8)    32          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 48, 1, 8)    32          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 48, 1, 8)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 48, 1, 8)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 48, 1, 8)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 48, 1, 8)     0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 48, 1, 8)     0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 48, 1, 8)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 48, 1, 24)    0           ['dropout_6[0][0]',              \n",
      "                                                                  'dropout_7[0][0]',              \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 24, 1, 24)   0           ['concatenate_1[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 24, 1, 12)    2304        ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 24, 1, 12)   48          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 24, 1, 12)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 12, 1, 12)   0           ['activation_9[0][0]']           \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 12, 1, 12)    0           ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 12, 1, 6)     288         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 12, 1, 6)    24          ['conv2d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 12, 1, 6)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 6, 1, 6)     0           ['activation_10[0][0]']          \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 6, 1, 6)      0           ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 36)           0           ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            74          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,154\n",
      "Trainable params: 21,926\n",
      "Non-trainable params: 228\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1680/1680 [==============================] - 261s 154ms/step - loss: 0.3237 - accuracy: 0.8763 - val_loss: 0.2421 - val_accuracy: 0.9126\n",
      "Epoch 2/500\n",
      "1680/1680 [==============================] - 279s 166ms/step - loss: 0.2442 - accuracy: 0.9093 - val_loss: 0.2141 - val_accuracy: 0.9223\n",
      "Epoch 3/500\n",
      "1680/1680 [==============================] - 268s 160ms/step - loss: 0.2247 - accuracy: 0.9167 - val_loss: 0.2066 - val_accuracy: 0.9250\n",
      "Epoch 4/500\n",
      "1680/1680 [==============================] - 273s 163ms/step - loss: 0.2169 - accuracy: 0.9203 - val_loss: 0.2041 - val_accuracy: 0.9269\n",
      "Epoch 5/500\n",
      "1680/1680 [==============================] - 260s 155ms/step - loss: 0.2096 - accuracy: 0.9220 - val_loss: 0.2048 - val_accuracy: 0.9257\n",
      "Epoch 6/500\n",
      "1680/1680 [==============================] - 264s 157ms/step - loss: 0.2062 - accuracy: 0.9242 - val_loss: 0.1935 - val_accuracy: 0.9278\n",
      "Epoch 7/500\n",
      "1680/1680 [==============================] - 264s 157ms/step - loss: 0.2021 - accuracy: 0.9247 - val_loss: 0.1950 - val_accuracy: 0.9287\n",
      "Epoch 8/500\n",
      "1680/1680 [==============================] - 265s 158ms/step - loss: 0.1962 - accuracy: 0.9275 - val_loss: 0.1911 - val_accuracy: 0.9299\n",
      "Epoch 9/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1931 - accuracy: 0.9281 - val_loss: 0.1931 - val_accuracy: 0.9287\n",
      "Epoch 10/500\n",
      "1680/1680 [==============================] - 257s 153ms/step - loss: 0.1894 - accuracy: 0.9303 - val_loss: 0.1901 - val_accuracy: 0.9295\n",
      "Epoch 11/500\n",
      "1680/1680 [==============================] - 258s 154ms/step - loss: 0.1868 - accuracy: 0.9300 - val_loss: 0.1880 - val_accuracy: 0.9283\n",
      "Epoch 12/500\n",
      "1680/1680 [==============================] - 258s 153ms/step - loss: 0.1851 - accuracy: 0.9308 - val_loss: 0.1807 - val_accuracy: 0.9330\n",
      "Epoch 13/500\n",
      "1680/1680 [==============================] - 264s 157ms/step - loss: 0.1789 - accuracy: 0.9342 - val_loss: 0.1774 - val_accuracy: 0.9351\n",
      "Epoch 14/500\n",
      "1680/1680 [==============================] - 253s 150ms/step - loss: 0.1791 - accuracy: 0.9330 - val_loss: 0.1833 - val_accuracy: 0.9327\n",
      "Epoch 15/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1759 - accuracy: 0.9349 - val_loss: 0.1794 - val_accuracy: 0.9354\n",
      "Epoch 16/500\n",
      "1680/1680 [==============================] - 251s 150ms/step - loss: 0.1755 - accuracy: 0.9350 - val_loss: 0.1784 - val_accuracy: 0.9342\n",
      "Epoch 17/500\n",
      "1680/1680 [==============================] - 251s 150ms/step - loss: 0.1719 - accuracy: 0.9369 - val_loss: 0.1830 - val_accuracy: 0.9326\n",
      "Epoch 18/500\n",
      "1680/1680 [==============================] - 251s 149ms/step - loss: 0.1700 - accuracy: 0.9369 - val_loss: 0.1767 - val_accuracy: 0.9348\n",
      "Epoch 19/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1690 - accuracy: 0.9381 - val_loss: 0.1775 - val_accuracy: 0.9353\n",
      "Epoch 20/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1674 - accuracy: 0.9385 - val_loss: 0.1733 - val_accuracy: 0.9359\n",
      "Epoch 21/500\n",
      "1680/1680 [==============================] - 251s 150ms/step - loss: 0.1638 - accuracy: 0.9389 - val_loss: 0.1734 - val_accuracy: 0.9357\n",
      "Epoch 22/500\n",
      "1680/1680 [==============================] - 253s 150ms/step - loss: 0.1609 - accuracy: 0.9410 - val_loss: 0.1728 - val_accuracy: 0.9371\n",
      "Epoch 23/500\n",
      "1680/1680 [==============================] - 253s 151ms/step - loss: 0.1592 - accuracy: 0.9411 - val_loss: 0.1716 - val_accuracy: 0.9360\n",
      "Epoch 24/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1595 - accuracy: 0.9408 - val_loss: 0.1690 - val_accuracy: 0.9394\n",
      "Epoch 25/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1582 - accuracy: 0.9428 - val_loss: 0.1799 - val_accuracy: 0.9342\n",
      "Epoch 26/500\n",
      "1680/1680 [==============================] - 258s 154ms/step - loss: 0.1541 - accuracy: 0.9425 - val_loss: 0.1687 - val_accuracy: 0.9381\n",
      "Epoch 27/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1507 - accuracy: 0.9443 - val_loss: 0.1720 - val_accuracy: 0.9351\n",
      "Epoch 28/500\n",
      "1680/1680 [==============================] - 251s 150ms/step - loss: 0.1545 - accuracy: 0.9430 - val_loss: 0.1680 - val_accuracy: 0.9385\n",
      "Epoch 29/500\n",
      "1680/1680 [==============================] - 254s 151ms/step - loss: 0.1525 - accuracy: 0.9434 - val_loss: 0.1674 - val_accuracy: 0.9396\n",
      "Epoch 30/500\n",
      "1680/1680 [==============================] - 251s 149ms/step - loss: 0.1478 - accuracy: 0.9458 - val_loss: 0.1683 - val_accuracy: 0.9375\n",
      "Epoch 31/500\n",
      "1680/1680 [==============================] - 250s 149ms/step - loss: 0.1470 - accuracy: 0.9453 - val_loss: 0.1699 - val_accuracy: 0.9372\n",
      "Epoch 32/500\n",
      "1680/1680 [==============================] - 250s 149ms/step - loss: 0.1487 - accuracy: 0.9452 - val_loss: 0.1685 - val_accuracy: 0.9397\n",
      "Epoch 33/500\n",
      "1680/1680 [==============================] - 250s 149ms/step - loss: 0.1446 - accuracy: 0.9462 - val_loss: 0.1721 - val_accuracy: 0.9344\n",
      "Epoch 34/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1442 - accuracy: 0.9464 - val_loss: 0.1683 - val_accuracy: 0.9384\n",
      "Epoch 35/500\n",
      "1680/1680 [==============================] - 251s 149ms/step - loss: 0.1438 - accuracy: 0.9455 - val_loss: 0.1657 - val_accuracy: 0.9371\n",
      "Epoch 36/500\n",
      "1680/1680 [==============================] - 251s 150ms/step - loss: 0.1432 - accuracy: 0.9485 - val_loss: 0.1648 - val_accuracy: 0.9399\n",
      "Epoch 37/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1391 - accuracy: 0.9491 - val_loss: 0.1620 - val_accuracy: 0.9393\n",
      "Epoch 38/500\n",
      "1680/1680 [==============================] - 251s 150ms/step - loss: 0.1416 - accuracy: 0.9472 - val_loss: 0.1652 - val_accuracy: 0.9368\n",
      "Epoch 39/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1392 - accuracy: 0.9499 - val_loss: 0.1669 - val_accuracy: 0.9376\n",
      "Epoch 40/500\n",
      "1680/1680 [==============================] - 255s 152ms/step - loss: 0.1391 - accuracy: 0.9497 - val_loss: 0.1672 - val_accuracy: 0.9393\n",
      "Epoch 41/500\n",
      "1680/1680 [==============================] - 252s 150ms/step - loss: 0.1373 - accuracy: 0.9494 - val_loss: 0.1638 - val_accuracy: 0.9400\n",
      "Epoch 42/500\n",
      "1680/1680 [==============================] - 280s 167ms/step - loss: 0.1370 - accuracy: 0.9503 - val_loss: 0.1656 - val_accuracy: 0.9394\n",
      "Epoch 43/500\n",
      "1680/1680 [==============================] - 263s 157ms/step - loss: 0.1327 - accuracy: 0.9514 - val_loss: 0.1723 - val_accuracy: 0.9382\n",
      "Epoch 44/500\n",
      "1680/1680 [==============================] - 257s 153ms/step - loss: 0.1358 - accuracy: 0.9488 - val_loss: 0.1676 - val_accuracy: 0.9393\n",
      "Epoch 45/500\n",
      "1680/1680 [==============================] - 253s 150ms/step - loss: 0.1333 - accuracy: 0.9499 - val_loss: 0.1670 - val_accuracy: 0.9403\n",
      "Epoch 46/500\n",
      "1680/1680 [==============================] - 253s 150ms/step - loss: 0.1335 - accuracy: 0.9508 - val_loss: 0.1650 - val_accuracy: 0.9412\n",
      "Epoch 47/500\n",
      "1680/1680 [==============================] - 253s 151ms/step - loss: 0.1345 - accuracy: 0.9499 - val_loss: 0.1612 - val_accuracy: 0.9417\n",
      "Epoch 48/500\n",
      "1680/1680 [==============================] - 257s 153ms/step - loss: 0.1314 - accuracy: 0.9522 - val_loss: 0.1673 - val_accuracy: 0.9403\n",
      "Epoch 49/500\n",
      "1680/1680 [==============================] - 262s 156ms/step - loss: 0.1319 - accuracy: 0.9521 - val_loss: 0.1651 - val_accuracy: 0.9406\n",
      "Epoch 50/500\n",
      "1680/1680 [==============================] - 268s 159ms/step - loss: 0.1313 - accuracy: 0.9509 - val_loss: 0.1658 - val_accuracy: 0.9417\n",
      "Epoch 51/500\n",
      "1680/1680 [==============================] - 260s 155ms/step - loss: 0.1293 - accuracy: 0.9514 - val_loss: 0.1702 - val_accuracy: 0.9388\n",
      "Epoch 52/500\n",
      "1680/1680 [==============================] - 268s 160ms/step - loss: 0.1282 - accuracy: 0.9525 - val_loss: 0.1672 - val_accuracy: 0.9393\n",
      "Epoch 53/500\n",
      "1680/1680 [==============================] - 259s 154ms/step - loss: 0.1276 - accuracy: 0.9526 - val_loss: 0.1652 - val_accuracy: 0.9405\n",
      "Epoch 54/500\n",
      "1680/1680 [==============================] - 262s 156ms/step - loss: 0.1248 - accuracy: 0.9533 - val_loss: 0.1647 - val_accuracy: 0.9385\n",
      "Epoch 55/500\n",
      "1680/1680 [==============================] - 254s 151ms/step - loss: 0.1266 - accuracy: 0.9522 - val_loss: 0.1593 - val_accuracy: 0.9421\n",
      "Epoch 56/500\n",
      "1680/1680 [==============================] - 258s 154ms/step - loss: 0.1273 - accuracy: 0.9528 - val_loss: 0.1671 - val_accuracy: 0.9412\n",
      "Epoch 57/500\n",
      "1680/1680 [==============================] - 265s 158ms/step - loss: 0.1236 - accuracy: 0.9537 - val_loss: 0.1605 - val_accuracy: 0.9412\n",
      "Epoch 58/500\n",
      "1680/1680 [==============================] - 265s 158ms/step - loss: 0.1232 - accuracy: 0.9532 - val_loss: 0.1619 - val_accuracy: 0.9411\n",
      "Epoch 59/500\n",
      "1680/1680 [==============================] - 262s 156ms/step - loss: 0.1232 - accuracy: 0.9555 - val_loss: 0.1695 - val_accuracy: 0.9388\n",
      "Epoch 60/500\n",
      "1680/1680 [==============================] - 256s 153ms/step - loss: 0.1228 - accuracy: 0.9534 - val_loss: 0.1710 - val_accuracy: 0.9387\n",
      "Epoch 61/500\n",
      "1680/1680 [==============================] - 261s 155ms/step - loss: 0.1206 - accuracy: 0.9543 - val_loss: 0.1698 - val_accuracy: 0.9385\n",
      "Epoch 62/500\n",
      "1680/1680 [==============================] - 259s 154ms/step - loss: 0.1219 - accuracy: 0.9542 - val_loss: 0.1794 - val_accuracy: 0.9396\n",
      "Epoch 63/500\n",
      "1680/1680 [==============================] - 260s 155ms/step - loss: 0.1213 - accuracy: 0.9558 - val_loss: 0.1701 - val_accuracy: 0.9391\n",
      "Epoch 64/500\n",
      "1680/1680 [==============================] - 269s 160ms/step - loss: 0.1229 - accuracy: 0.9550 - val_loss: 0.1731 - val_accuracy: 0.9385\n",
      "Epoch 65/500\n",
      "1680/1680 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9543Restoring model weights from the end of the best epoch: 55.\n",
      "1680/1680 [==============================] - 258s 154ms/step - loss: 0.1221 - accuracy: 0.9543 - val_loss: 0.1629 - val_accuracy: 0.9432\n",
      "Epoch 00065: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 21:31:17.364445: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = EEGInception(\n",
    "   input_time=1000, fs=192, ncha=32, filters_per_branch=8,\n",
    "   scales_time=(500, 250, 125), dropout_rate=0.25,\n",
    "   activation='elu', n_classes=2, learning_rate=0.001)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.0001,\n",
    "    mode='min', patience=10, verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Fit model\n",
    "fit_hist = model.fit(features,\n",
    "                     train_erp_labels,\n",
    "                     epochs=500,\n",
    "                     batch_size=16,\n",
    "                     validation_split=0.2,\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "# Save\n",
    "model.save('model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1de64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.945476 \n",
      "Overall Categorical Accuracy: 94.55%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non-Attended</th>\n",
       "      <td>0.961154</td>\n",
       "      <td>0.974041</td>\n",
       "      <td>0.967555</td>\n",
       "      <td>7011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attended</th>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.801296</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>1389.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Precision    Recall   F-Score  Support\n",
       "Non-Attended   0.961154  0.974041  0.967555   7011.0\n",
       "Attended       0.859459  0.801296  0.829359   1389.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"EEG Inception Classification accuracy: %f \" % (acc))\n",
    "\n",
    "\n",
    "names        = ['Non-Attended', 'Attended']\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "    \n",
    "def display_results(y_true, y_preds, class_labels):\n",
    "    \n",
    "    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n",
    "                          columns=class_labels).T\n",
    "\n",
    "    results.rename(columns={0: 'Precision', 1: 'Recall',\n",
    "                            2: 'F-Score', 3: 'Support'}, inplace=True)\n",
    "    \n",
    "    results.sort_values(by='F-Score', ascending=False, inplace=True)                           \n",
    "    global_acc = accuracy_score(y_true, y_preds)\n",
    "    \n",
    "    print(\"Overall Categorical Accuracy: {:.2f}%\".format(global_acc*100))\n",
    "    return results\n",
    "display_results(Y_test.argmax(axis = -1), preds, names)\n",
    "#display_results(Y_test.argmax(axis=-1), preds, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23581ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_heatmap(y_true, y_pred, class_names, ax, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.set(font_scale=1.0)\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        square=True, \n",
    "        xticklabels=class_names, \n",
    "        yticklabels=class_names,\n",
    "        fmt='d', \n",
    "        cmap=plt.cm.Blues,\n",
    "        cbar=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title + \": Confusion Matrix\", fontsize=12)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha=\"right\")\n",
    "    ax.set_ylabel('Predicted Label', fontsize=12)\n",
    "    ax.set_xlabel('True Label', fontsize=12)\n",
    "\n",
    "plt.figure(0)\n",
    "fig, (ax3) = plt.subplots(1, 1, figsize=(6, 5))\n",
    "plot_heatmap(preds,Y_test.argmax(axis=-1), names, ax3, title = 'LDA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035f0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject_008', '.DS_Store', 'subject_009', 'subject_007', 'subject_014', 'subject_013', 'subject_012', 'subject_015', 'subject_002', 'subject_005', 'subject_004', 'subject_019', 'subject_017', 'subject_016', 'subject_011', 'subject_018']\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.912500 \n",
      "EEGInception Overall Categorical Accuracy: 91.25%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.962453  0.931333  0.946637   3000.0\n",
      "Attended       0.704448  0.818333  0.757132    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.947500 \n",
      "EEGInception Overall Categorical Accuracy: 94.75%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.962488   0.975  0.968703   3000.0\n",
      "Attended       0.866310   0.810  0.837209    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/.DS_Store\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.845278 \n",
      "EEGInception Overall Categorical Accuracy: 84.53%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.865172  0.964667  0.912214   3000.0\n",
      "Attended       0.584314  0.248333  0.348538    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:220\n",
      "no of non_attended P300 events:1100\n",
      "no of labled P300 events:220\n",
      "no of non_attended P300 events:1100\n",
      "(2640, 192, 32)\n",
      "(2640,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.935227 \n",
      "EEGInception Overall Categorical Accuracy: 93.52%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.943207  0.981364  0.961907   2200.0\n",
      "Attended       0.883191  0.704545  0.783818    440.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.940000 \n",
      "EEGInception Overall Categorical Accuracy: 94.00%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.971066  0.9565  0.963728   2000.0\n",
      "Attended       0.797674  0.8575  0.826506    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.913056 \n",
      "EEGInception Overall Categorical Accuracy: 91.31%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.923951  0.976000  0.949262   3000.0\n",
      "Attended       0.832947  0.598333  0.696411    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.965000 \n",
      "EEGInception Overall Categorical Accuracy: 96.50%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.965953   0.993  0.979290   3000.0\n",
      "Attended       0.959302   0.825  0.887097    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.975833 \n",
      "EEGInception Overall Categorical Accuracy: 97.58%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.978640  0.992667  0.985603   3000.0\n",
      "Attended       0.960503  0.891667  0.924806    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.887500 \n",
      "EEGInception Overall Categorical Accuracy: 88.75%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.948187   0.915  0.931298   2000.0\n",
      "Attended       0.638298   0.750  0.689655    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.843750 \n",
      "EEGInception Overall Categorical Accuracy: 84.38%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.889688  0.9275  0.908201   2000.0\n",
      "Attended       0.539683  0.4250  0.475524    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.916667 \n",
      "EEGInception Overall Categorical Accuracy: 91.67%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.955927  0.9435  0.949673   2000.0\n",
      "Attended       0.734742  0.7825  0.757869    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.890417 \n",
      "EEGInception Overall Categorical Accuracy: 89.04%\n",
      "              Precision  Recall  F-Score  Support\n",
      "Non-Attended   0.941985  0.9255  0.93367   2000.0\n",
      "Attended       0.657471  0.7150  0.68503    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.926250 \n",
      "EEGInception Overall Categorical Accuracy: 92.62%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.955978  0.9555  0.955739   2000.0\n",
      "Attended       0.778055  0.7800  0.779026    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.850000 \n",
      "EEGInception Overall Categorical Accuracy: 85.00%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.918817  0.899474  0.909043   3800.0\n",
      "Attended       0.545238  0.602632  0.572500    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.951111 \n",
      "EEGInception Overall Categorical Accuracy: 95.11%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.962647  0.979333  0.970919   3000.0\n",
      "Attended       0.886861  0.810000  0.846690    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.870000 \n",
      "EEGInception Overall Categorical Accuracy: 87.00%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.929735   0.913  0.921292   2000.0\n",
      "Attended       0.600917   0.655  0.626794    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.907018 \n",
      "EEGInception Overall Categorical Accuracy: 90.70%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.927342  0.963947  0.945290   3800.0\n",
      "Attended       0.775410  0.622368  0.690511    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:180\n",
      "no of non_attended P300 events:900\n",
      "no of labled P300 events:180\n",
      "no of non_attended P300 events:900\n",
      "(2160, 192, 32)\n",
      "(2160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.906481 \n",
      "EEGInception Overall Categorical Accuracy: 90.65%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.917887  0.975000  0.945582   1800.0\n",
      "Attended       0.818548  0.563889  0.667763    360.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.930000 \n",
      "EEGInception Overall Categorical Accuracy: 93.00%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.964817  0.950667  0.957690   3000.0\n",
      "Attended       0.770186  0.826667  0.797428    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.941389 \n",
      "EEGInception Overall Categorical Accuracy: 94.14%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.981360  0.947667  0.964219   3000.0\n",
      "Attended       0.776671  0.910000  0.838066    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.901250 \n",
      "EEGInception Overall Categorical Accuracy: 90.12%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.924002  0.9605  0.941898   2000.0\n",
      "Attended       0.753894  0.6050  0.671290    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.885000 \n",
      "EEGInception Overall Categorical Accuracy: 88.50%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.950837   0.909  0.929448   2000.0\n",
      "Attended       0.627049   0.765  0.689189    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.877500 \n",
      "EEGInception Overall Categorical Accuracy: 87.75%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.901979   0.957  0.928675   2000.0\n",
      "Attended       0.690647   0.480  0.566372    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.821053 \n",
      "EEGInception Overall Categorical Accuracy: 82.11%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.867126  0.927368  0.896236   3800.0\n",
      "Attended       0.443548  0.289474  0.350318    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.868333 \n",
      "EEGInception Overall Categorical Accuracy: 86.83%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.884826   0.968  0.924546   3000.0\n",
      "Attended       0.698113   0.370  0.483660    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.917222 \n",
      "EEGInception Overall Categorical Accuracy: 91.72%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.928889  0.975333  0.951545   3000.0\n",
      "Attended       0.835556  0.626667  0.716190    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.932500 \n",
      "EEGInception Overall Categorical Accuracy: 93.25%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.947856  0.9725  0.960020   2000.0\n",
      "Attended       0.841954  0.7325  0.783422    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.928070 \n",
      "EEGInception Overall Categorical Accuracy: 92.81%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.943763  0.971579  0.957469   3800.0\n",
      "Attended       0.833333  0.710526  0.767045    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.831389 \n",
      "EEGInception Overall Categorical Accuracy: 83.14%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.862246  0.949333  0.903697   3000.0\n",
      "Attended       0.488215  0.241667  0.323300    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.941944 \n",
      "EEGInception Overall Categorical Accuracy: 94.19%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.945704  0.987000  0.965911   3000.0\n",
      "Attended       0.916844  0.716667  0.804490    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.899583 \n",
      "EEGInception Overall Categorical Accuracy: 89.96%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.925908  0.9560  0.940713   2000.0\n",
      "Attended       0.737313  0.6175  0.672109    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:220\n",
      "no of non_attended P300 events:1100\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:220\n",
      "no of non_attended P300 events:1100\n",
      "(5040, 192, 32)\n",
      "(5040,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.925000 \n",
      "EEGInception Overall Categorical Accuracy: 92.50%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.932745  0.980714  0.956128   4200.0\n",
      "Attended       0.870192  0.646429  0.741803    840.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.937917 \n",
      "EEGInception Overall Categorical Accuracy: 93.79%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.939250  0.9895  0.963720   2000.0\n",
      "Attended       0.928328  0.6800  0.784993    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.895417 \n",
      "EEGInception Overall Categorical Accuracy: 89.54%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.911529  0.9685  0.939152   2000.0\n",
      "Attended       0.770909  0.5300  0.628148    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.912500 \n",
      "EEGInception Overall Categorical Accuracy: 91.25%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.940887   0.955  0.947891   2000.0\n",
      "Attended       0.756757   0.700  0.727273    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.955417 \n",
      "EEGInception Overall Categorical Accuracy: 95.54%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.980213  0.9660  0.973055   2000.0\n",
      "Attended       0.841492  0.9025  0.870929    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.965000 \n",
      "EEGInception Overall Categorical Accuracy: 96.50%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.981407  0.9765  0.978947   2000.0\n",
      "Attended       0.885366  0.9075  0.896296    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.935833 \n",
      "EEGInception Overall Categorical Accuracy: 93.58%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.959814  0.963333  0.961570   3000.0\n",
      "Attended       0.813243  0.798333  0.805719    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:220\n",
      "no of non_attended P300 events:1100\n",
      "(2520, 192, 32)\n",
      "(2520,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.868254 \n",
      "EEGInception Overall Categorical Accuracy: 86.83%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.904022  0.941905  0.922575   2100.0\n",
      "Attended       0.632530  0.500000  0.558511    420.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.869167 \n",
      "EEGInception Overall Categorical Accuracy: 86.92%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.937241  0.9035  0.920061   2000.0\n",
      "Attended       0.591102  0.6975  0.639908    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.928750 \n",
      "EEGInception Overall Categorical Accuracy: 92.88%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.952947  0.9620  0.957452   2000.0\n",
      "Attended       0.800525  0.7625  0.781050    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.899583 \n",
      "EEGInception Overall Categorical Accuracy: 89.96%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.943073  0.9360  0.939523   2000.0\n",
      "Attended       0.691566  0.7175  0.704294    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.950417 \n",
      "EEGInception Overall Categorical Accuracy: 95.04%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.984045  0.9560  0.969820   2000.0\n",
      "Attended       0.807440  0.9225  0.861144    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.938611 \n",
      "EEGInception Overall Categorical Accuracy: 93.86%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.977656  0.948000  0.962599   3000.0\n",
      "Attended       0.774240  0.891667  0.828815    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.949167 \n",
      "EEGInception Overall Categorical Accuracy: 94.92%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.966700  0.9725  0.969591   2000.0\n",
      "Attended       0.858247  0.8325  0.845178    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.876667 \n",
      "EEGInception Overall Categorical Accuracy: 87.67%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.898628  0.960333  0.928456   3000.0\n",
      "Attended       0.697970  0.458333  0.553320    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.934444 \n",
      "EEGInception Overall Categorical Accuracy: 93.44%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.950456  0.972000  0.961107   3000.0\n",
      "Attended       0.842105  0.746667  0.791519    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.930000 \n",
      "EEGInception Overall Categorical Accuracy: 93.00%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.954967  0.961333  0.958140   3000.0\n",
      "Attended       0.800000  0.773333  0.786441    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.835000 \n",
      "EEGInception Overall Categorical Accuracy: 83.50%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.879017    0.93  0.903790   2000.0\n",
      "Attended       0.507042    0.36  0.421053    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.904444 \n",
      "EEGInception Overall Categorical Accuracy: 90.44%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.900966  0.994667  0.945501   3000.0\n",
      "Attended       0.944444  0.453333  0.612613    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.899561 \n",
      "EEGInception Overall Categorical Accuracy: 89.96%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.924759  0.957368  0.940781   3800.0\n",
      "Attended       0.741214  0.610526  0.669553    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.939912 \n",
      "EEGInception Overall Categorical Accuracy: 93.99%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.952748  0.976316  0.964388   3800.0\n",
      "Attended       0.864865  0.757895  0.807854    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.938377 \n",
      "EEGInception Overall Categorical Accuracy: 93.84%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.979558  0.945789  0.962378   3800.0\n",
      "Attended       0.768799  0.901316  0.829800    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.956389 \n",
      "EEGInception Overall Categorical Accuracy: 95.64%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.983997  0.963333  0.973556   3000.0\n",
      "Attended       0.834087  0.921667  0.875693    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.828889 \n",
      "EEGInception Overall Categorical Accuracy: 82.89%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.846713  0.970333  0.904318   3000.0\n",
      "Attended       0.450617  0.121667  0.191601    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.934167 \n",
      "EEGInception Overall Categorical Accuracy: 93.42%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.941233  0.982333  0.961344   3000.0\n",
      "Attended       0.886994  0.693333  0.778297    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.870614 \n",
      "EEGInception Overall Categorical Accuracy: 87.06%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.922368  0.922368  0.922368   3800.0\n",
      "Attended       0.611842  0.611842  0.611842    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "no of labled P300 events:380\n",
      "no of non_attended P300 events:1900\n",
      "(4560, 192, 32)\n",
      "(4560,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.840132 \n",
      "EEGInception Overall Categorical Accuracy: 84.01%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.865508  0.956842  0.908886   3800.0\n",
      "Attended       0.543175  0.256579  0.348525    760.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(2400, 192, 32)\n",
      "(2400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.809583 \n",
      "EEGInception Overall Categorical Accuracy: 80.96%\n",
      "              Precision  Recall   F-Score  Support\n",
      "Non-Attended   0.878743  0.8950  0.886797   2000.0\n",
      "Attended       0.421488  0.3825  0.401048    400.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "(3600, 192, 32)\n",
      "(3600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Inception Classification accuracy: 0.964167 \n",
      "EEGInception Overall Categorical Accuracy: 96.42%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.961724  0.996667  0.978884   3000.0\n",
      "Attended       0.979633  0.801667  0.881760    600.0\n",
      "/users/raviravipati/Desktop/eeg-data/CV-test/subject_042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n",
      "WARNING: failed to interpret \"auto\" as type int in parameter \"VisualizeSourceBufferSize\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:200\n",
      "no of non_attended P300 events:1000\n",
      "no of labled P300 events:180\n",
      "no of non_attended P300 events:900\n",
      "(3480, 192, 32)\n",
      "(3480,)\n",
      "EEG Inception Classification accuracy: 0.960057 \n",
      "EEGInception Overall Categorical Accuracy: 96.01%\n",
      "              Precision    Recall   F-Score  Support\n",
      "Non-Attended   0.993565  0.958276  0.975601   2900.0\n",
      "Attended       0.822840  0.968966  0.889945    580.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy import stats\n",
    "import os\n",
    "print (list_dir)\n",
    "from BCI2kReader import BCI2kReader as b2k \n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "#subject_name = 'subject_048'\n",
    "src_dir = '../Desktop/eeg-data/CV-test/' \n",
    "#out_dir = 'Desktop/eeg-data/output/'+ subject_name +'_results.pdf'\n",
    "list_dir1 = os.listdir(src_dir)\n",
    "\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "f=open('../Desktop/eeg-data/eeginception-cv.csv', 'w')\n",
    "csv_writer = csv.writer(f)\n",
    "\n",
    "\n",
    "def display_results(y_true, y_preds, class_labels,method, subject):\n",
    "    \n",
    "    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n",
    "                          columns=class_labels).T\n",
    "\n",
    "    results.rename(columns={0: 'Precision', 1: 'Recall',\n",
    "                            2: 'F-Score', 3: 'Support'}, inplace=True)\n",
    "    \n",
    "    results.sort_values(by='F-Score', ascending=False, inplace=True)                           \n",
    "    global_acc = accuracy_score(y_true, y_preds)\n",
    "    \n",
    "    print(method + \" Overall Categorical Accuracy: {:.2f}%\".format(global_acc*100))\n",
    "    print(results)\n",
    "    data1=[subject,global_acc,results.iat[1,0],results.iat[1,1],results.iat[1,2], results.iat[1,3]]\n",
    "    csv_writer.writerow(data1)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_data(subject_to_signals) :\n",
    "\n",
    "# Prepare the data for training\n",
    "# Train data is for EEGNet trainng & testing as well as RG+xDawn evaluation\n",
    "#192 temporal data points are used for EEGNet \n",
    "#Iterative work pointed that 128 temporal points for ech event produced gives best LDA performance\n",
    "\n",
    "    window = 192   #Signal time series window\n",
    "    sht_window = 128 # shoretened window for LDA analysis\n",
    "    subject_name = []\n",
    "    z_score = []\n",
    "    zerozscore = []\n",
    "    #print (subject_to_signals)\n",
    "    array_elements = sht_window * 32\n",
    "\n",
    "    #Train_data = np.array(np.empty((0,32,window), float))  # Training data array initialization\n",
    "    Train_data = np.array(np.empty((0,window,32), float))  # Training data array initialization\n",
    "\n",
    "    Train_labels = []   # Training label data initialization\n",
    "    Train_data_flattened = np.array(np.empty((0,array_elements), float))  # Training data array initialization\n",
    "\n",
    "\n",
    "\n",
    "    for subject, my_signals in subject_to_signals.items():\n",
    "       # print (my_signals)\n",
    "        #Train_data_temp = np.array(np.empty((0,32,window), float))  # Training data array initialization\n",
    "        Train_data_temp = np.array(np.empty((0,window,32), float))  # Training data array initialization\n",
    "\n",
    "        Train_labels_temp = []   # Training label data initialization\n",
    "        Train_data_flattened_temp = np.array(np.empty((0,array_elements), float))  # Training data array initialization\n",
    "\n",
    "        stimuluscode = (my_signals[1]['StimulusCode']) #ndarrays ; target \n",
    "        stimulustype = (my_signals[1]['StimulusType']) #p3label\n",
    "        data = stimuluscode[0] #target numbers\n",
    "        data_label = stimulustype[0] #p3label numbers\n",
    "        rownum = len(data)\n",
    "        labelrow = len(data_label)\n",
    "        zerozscore = (-1*np.mean(my_signals[0])/(my_signals[0]).std())\n",
    "\n",
    "        change = [] #indexes of 0 where next index is nonzero for target\n",
    "        for x in range(rownum-1):    \n",
    "            if bool(data.item(x) == 0) and bool(data.item(x + 1) != 0): \n",
    "                    change.append(x)\n",
    "\n",
    "\n",
    "\n",
    "        attended = [] #indexes where p3label value is 1\n",
    "        nonattended = [] #indexes where p3label value is 0\n",
    "\n",
    "\n",
    "        nonattended_count =1\n",
    "\n",
    "        for x in range(len(change)): \n",
    "\n",
    "            attended_values = np.empty((0,window), float) #2D array with train data each row in same a time frame\n",
    "            nonattended_values = np.empty((0,window), float)\n",
    "            attended_values_sht = np.empty((0,sht_window), float) #2D array with train data each row in same a time frame\n",
    "            nonattended_values_sht = np.empty((0,sht_window), float)\n",
    "\n",
    "            if bool(data_label.item(change[x] + 1) == 0): \n",
    "                nonattended_count =nonattended_count +1    \n",
    "                nonattended.append(change[x])\n",
    "                Train_labels_temp.append(int(0))\n",
    "                for num in range(len(my_signals[0])):\n",
    "                    electrode = my_signals[0][num]\n",
    "                    zelectrode = stats.zscore(my_signals[0][num])\n",
    "                    nonattendedtemp = []\n",
    "                    nonattendedtemp_sht =[]\n",
    "                    if (change[x] + window) > len(zelectrode):\n",
    "                        addtime = len(zelectrode) - (change[x])            \n",
    "                        for y in range(addtime):\n",
    "                            nonattendedtemp.append(zelectrode[change[x] + y])\n",
    "                        for y in range(sht_window):\n",
    "                            nonattendedtemp_sht.append(zelectrode[change[x] + y])\n",
    "                        nonattended_values_sht = np.append(nonattended_values_sht, np.array([nonattendedtemp_sht]), axis = 0)               \n",
    "                        nonattended_values = np.append(nonattended_values, np.array([nonattendedtemp]), axis = 0)\n",
    "                    else:\n",
    "                        for y in range(window):\n",
    "                            nonattendedtemp.append(zelectrode[change[x] + y])\n",
    "                        for y in range(sht_window):\n",
    "                            nonattendedtemp_sht.append(zelectrode[change[x] + y])\n",
    "                    nonattended_values = np.append(nonattended_values, np.array([nonattendedtemp]), axis = 0)\n",
    "                    nonattended_values_sht = np.append(nonattended_values_sht, np.array([nonattendedtemp_sht]), axis = 0)               \n",
    "                #if nonattended_count % 5 == 0:\n",
    "                Train_data_flattened_temp = np.append(Train_data_flattened_temp, np.array([nonattended_values_sht.flatten()]), axis=0)\n",
    "                Train_data_temp = np.append(Train_data_temp,np.array([nonattended_values.T]), axis=0)\n",
    "            else: \n",
    "                attended.append(change[x] + 1) \n",
    "                Train_labels_temp.append(int(1))\n",
    "\n",
    "                for num in range(len(my_signals[0])):\n",
    "                    electrode = my_signals[0][num]\n",
    "                    zelectrode = stats.zscore(my_signals[0][num])\n",
    "                    attendedtemp = []\n",
    "                    attendedtemp_sht = []\n",
    "\n",
    "                    for y in range(window): \n",
    "                        attendedtemp.append(zelectrode[change[x] + y])\n",
    "                    for y in range(sht_window): \n",
    "                        attendedtemp_sht.append(zelectrode[change[x] + y])\n",
    "\n",
    "                    attended_values = np.append(attended_values, np.array([attendedtemp]), axis = 0)\n",
    "                    attended_values_sht = np.append(attended_values_sht, np.array([attendedtemp_sht]), axis = 0)\n",
    "\n",
    "                Train_data_flattened_temp = np.append( Train_data_flattened_temp, np.array([attended_values_sht.flatten()]), axis=0)\n",
    "                Train_data_temp = np.append( Train_data_temp,np.array([attended_values.T]), axis=0)        \n",
    "\n",
    "        Train_data_flattened = np.concatenate((Train_data_flattened, Train_data_flattened_temp),axis=0) # format is in (trials, channels, samples)\n",
    "        Train_data = np.concatenate((Train_data, Train_data_temp),axis=0) # format is in (trials, channels, samples)\n",
    "        Train_labels = np.concatenate((Train_labels, Train_labels_temp),axis=0) \n",
    "\n",
    "        print(\"no of labled P300 events:\"+str(len(attended)))\n",
    "        print(\"no of non_attended P300 events:\"+str(len(nonattended)))\n",
    "\n",
    "    print(np.shape(Train_data))\n",
    "    print(np.shape(Train_labels))\n",
    "    return Train_data, Train_labels    \n",
    "    \n",
    "\n",
    "for sub_root_dir in os.listdir(src_dir):\n",
    "    print(src_dir+sub_root_dir)\n",
    "    if not (sub_root_dir.startswith(\".\") or sub_root_dir in list_dir):\n",
    "        subject_to_signals =  {}  #dictionary; key= subject, value = data\n",
    "        for subject_dir in os.listdir(src_dir+sub_root_dir+'/')[0:85]:\n",
    "   \n",
    "            if not subject_dir.startswith(\".\"):\n",
    "                    if (subject_dir.endswith(\".dat\")):\n",
    "                        with b2k.BCI2kReader(src_dir+sub_root_dir+'/'+subject_dir, \"Inception-Bagging.dat\") as file: \n",
    "                            subject_to_signals[subject_dir] = file.read()\n",
    "        X_test, Y_test = get_data(subject_to_signals)\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "        Y_test = one_hot_labels(Y_test)    \n",
    "        probs       = model.predict(X_test)\n",
    "        preds       = probs.argmax(axis = -1)  \n",
    "        acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "        print(\"EEG Inception Classification accuracy: %f \" % (acc))\n",
    "        display_results(Y_test.argmax(axis = -1), preds, names , \"EEGInception\",sub_root_dir)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfca317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
